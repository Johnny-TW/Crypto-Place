import chainlit as cl
import httpx
import os
from typing import Dict, Any, Optional
import google.generativeai as genai
from dotenv import load_dotenv
from datetime import datetime
import time

# æ¢ä»¶å°å…¥ Langfuse (v3.x æ–°ç‰ˆå°å…¥æ–¹å¼)
try:
    from langfuse import observe, get_client
    LANGFUSE_AVAILABLE = True
except ImportError:
    LANGFUSE_AVAILABLE = False
    observe = None
    print("â„¹ï¸ Langfuse æœªå®‰è£ï¼Œç›£æ§åŠŸèƒ½å°‡è¢«åœç”¨")

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# é…ç½®
NESTJS_API = os.getenv("NESTJS_API_URL", "http://localhost:5001")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")
COINGECKO_API_KEY = os.getenv("COINGECKO_API_KEY", "CG-nrJXAB28gG2xbfsdLieGcxWB")
COINGECKO_API_BASE = "https://api.coingecko.com/api/v3"

# Langfuse é…ç½®
LANGFUSE_PUBLIC_KEY = os.getenv("LANGFUSE_PUBLIC_KEY")
LANGFUSE_SECRET_KEY = os.getenv("LANGFUSE_SECRET_KEY")
LANGFUSE_HOST = os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com")

# åˆå§‹åŒ– Gemini
genai.configure(api_key=GEMINI_API_KEY)

# ============ å¤šæ¨¡å‹ Fallback æ”¯æ´ ============
class GeminiModelManager:
    """
    Gemini æ¨¡å‹ç®¡ç†å™¨ - æ”¯æ´å¤šæ¨¡å‹ Fallback
    ç•¶ä¸€å€‹æ¨¡å‹é…é¡ç”¨ç›¡æ™‚ï¼Œè‡ªå‹•åˆ‡æ›åˆ°ä¸‹ä¸€å€‹å‚™ç”¨æ¨¡å‹
    """

    # æ”¯æ´çš„æ¨¡å‹åˆ—è¡¨ï¼ˆä¾å„ªå…ˆé †åºï¼‰
    # æ³¨æ„ï¼šä½¿ç”¨ Google AI Studio API (google.generativeai) æ™‚çš„æœ‰æ•ˆæ¨¡å‹åç¨±
    # æ›´æ–°æ–¼ 2024-12ï¼šåŠ å…¥ gemini-2.5 ç³»åˆ—
    FALLBACK_MODELS = [
        "gemini-2.5-flash",           # æœ€æ–°ç‰ˆæœ¬ (2024æœ€æ–°)
        "gemini-2.0-flash",           # ç©©å®šç‰ˆ
        "gemini-2.0-flash-lite",      # æ›´è¼•é‡ç‰ˆæœ¬
        "gemini-1.5-flash",           # 1.5 ç©©å®šç‰ˆ
        "gemini-1.5-pro",             # Pro ç‰ˆæœ¬
    ]

    def __init__(self, primary_model: str = None):
        self.primary_model = primary_model or GEMINI_MODEL
        self.current_model_name = self.primary_model
        self.models = {}
        self._init_models()

    def _init_models(self):
        """åˆå§‹åŒ–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
        # ç¢ºä¿ä¸»æ¨¡å‹åœ¨åˆ—è¡¨æœ€å‰é¢
        model_order = [self.primary_model] + [m for m in self.FALLBACK_MODELS if m != self.primary_model]

        for model_name in model_order:
            try:
                self.models[model_name] = genai.GenerativeModel(model_name)
                print(f"  âœ“ {model_name} å·²è¼‰å…¥")
            except Exception as e:
                print(f"  âœ— {model_name} è¼‰å…¥å¤±æ•—: {e}")

        print(f"ğŸ“¦ å·²è¼‰å…¥ {len(self.models)} å€‹æ¨¡å‹")

    def generate_content(self, prompt: str, max_retries: int = 3) -> Any:
        """
        ç”Ÿæˆå…§å®¹ï¼Œæ”¯æ´è‡ªå‹• Fallback

        Args:
            prompt: æç¤ºè©
            max_retries: æ¯å€‹æ¨¡å‹çš„æœ€å¤§é‡è©¦æ¬¡æ•¸

        Returns:
            Gemini API å›æ‡‰
        """
        errors = []

        for model_name, model in self.models.items():
            for attempt in range(max_retries):
                try:
                    response = model.generate_content(prompt)

                    # æˆåŠŸï¼æ›´æ–°ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹åç¨±
                    if self.current_model_name != model_name:
                        print(f"ğŸ”„ å·²åˆ‡æ›åˆ°æ¨¡å‹: {model_name}")
                        self.current_model_name = model_name

                    return response

                except Exception as e:
                    error_str = str(e)
                    errors.append(f"{model_name} (attempt {attempt + 1}): {error_str}")

                    # æª¢æŸ¥æ˜¯å¦ç‚ºé…é¡éŒ¯èª¤
                    if "429" in error_str or "quota" in error_str.lower() or "rate" in error_str.lower():
                        print(f"âš ï¸ {model_name} é…é¡å·²æ»¿ï¼Œå˜—è©¦ä¸‹ä¸€å€‹æ¨¡å‹...")
                        break  # è·³åˆ°ä¸‹ä¸€å€‹æ¨¡å‹

                    # å…¶ä»–éŒ¯èª¤ï¼Œç­‰å¾…å¾Œé‡è©¦
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 2  # æŒ‡æ•¸é€€é¿
                        print(f"â³ {model_name} éŒ¯èª¤ï¼Œ{wait_time}ç§’å¾Œé‡è©¦...")
                        time.sleep(wait_time)

        # æ‰€æœ‰æ¨¡å‹éƒ½å¤±æ•—äº†
        raise Exception(f"æ‰€æœ‰æ¨¡å‹éƒ½ç„¡æ³•ä½¿ç”¨:\n" + "\n".join(errors))

    @property
    def current_model(self) -> str:
        """å–å¾—ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹åç¨±"""
        return self.current_model_name

# å»ºç«‹æ¨¡å‹ç®¡ç†å™¨ï¼ˆå–ä»£åŸæœ¬çš„å–®ä¸€æ¨¡å‹ï¼‰
print(f"ğŸ¤– åˆå§‹åŒ– Gemini æ¨¡å‹ç®¡ç†å™¨...")
gemini_manager = GeminiModelManager(GEMINI_MODEL)
# ä¿æŒå‘å¾Œç›¸å®¹
gemini_model = gemini_manager

# æª¢æŸ¥ Langfuse æ˜¯å¦å¯ç”¨
langfuse_enabled = False
if LANGFUSE_AVAILABLE and LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY:
    # è¨­å®š Langfuse ç’°å¢ƒè®Šæ•¸ (decorators æœƒè‡ªå‹•ä½¿ç”¨)
    os.environ["LANGFUSE_PUBLIC_KEY"] = LANGFUSE_PUBLIC_KEY
    os.environ["LANGFUSE_SECRET_KEY"] = LANGFUSE_SECRET_KEY
    os.environ["LANGFUSE_HOST"] = LANGFUSE_HOST
    langfuse_enabled = True
    print(f"âœ… Langfuse ç›£æ§å·²å•Ÿç”¨")
else:
    if not LANGFUSE_AVAILABLE:
        print(f"â„¹ï¸ Langfuse ç›£æ§æœªå•Ÿç”¨ (å¥—ä»¶æœªå®‰è£)")
    else:
        print(f"â„¹ï¸ Langfuse ç›£æ§æœªå•Ÿç”¨ (æœªè¨­å®šé‡‘é‘°)")

print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {GEMINI_MODEL}")

# NestJS API èª¿ç”¨å‡½æ•¸
async def call_nestjs_api(
    endpoint: str,
    method: str = "GET",
    data: Optional[Dict] = None,
    token: Optional[str] = None
) -> Optional[Dict[str, Any]]:
    """é€šç”¨ NestJS API èª¿ç”¨å‡½æ•¸"""
    url = f"{NESTJS_API}{endpoint}"
    headers = {}
    
    if token:
        headers["Authorization"] = f"Bearer {token}"
    
    async with httpx.AsyncClient() as client:
        try:
            if method == "GET":
                response = await client.get(url, headers=headers, timeout=10.0)
            elif method == "POST":
                response = await client.post(url, json=data, headers=headers, timeout=10.0)
            else:
                raise ValueError(f"Unsupported method: {method}")
            
            response.raise_for_status()
            return response.json()
        except httpx.HTTPError as e:
            print(f"API Error: {e}")
            return None

async def get_coin_data(coin_id: str) -> Optional[Dict[str, Any]]:
    """ç²å–åŠ å¯†è²¨å¹£æ•¸æ“š"""
    return await call_nestjs_api(f"/api/coins/{coin_id}")

async def get_user_watchlist(token: str) -> Optional[list]:
    """ç²å–ç”¨æˆ¶ watchlist"""
    result = await call_nestjs_api("/api/watchlist", token=token)
    return result if result else []

async def search_coins(query: str) -> Optional[list]:
    """æœå°‹åŠ å¯†è²¨å¹£"""
    return await call_nestjs_api(f"/api/search?q={query}")

# CoinGecko API ç›´æ¥èª¿ç”¨å‡½æ•¸

async def fetch_coingecko_data(endpoint: str, params: Optional[Dict] = None) -> Optional[Dict[str, Any]]:
    """ç›´æ¥èª¿ç”¨ CoinGecko API"""
    url = f"{COINGECKO_API_BASE}{endpoint}"
    headers = {
        "accept": "application/json",
        "x-cg-demo-api-key": COINGECKO_API_KEY
    }
    
    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(url, headers=headers, params=params, timeout=15.0)
            response.raise_for_status()
            return response.json()
        except httpx.HTTPError as e:
            print(f"CoinGecko API Error: {e}")
            return None

async def get_crypto_price(coin_id: str) -> Optional[Dict[str, Any]]:
    """ç²å–å–®ä¸€åŠ å¯†è²¨å¹£çš„å³æ™‚åƒ¹æ ¼å’Œå¸‚å ´è³‡è¨Š"""
    data = await fetch_coingecko_data(
        f"/coins/{coin_id}",
        params={
            "localization": "false",
            "tickers": "false",
            "market_data": "true",
            "community_data": "false",
            "developer_data": "false"
        }
    )
    
    if not data:
        return None
    
    # æå–é—œéµå¸‚å ´è³‡æ–™
    market_data = data.get("market_data", {})
    return {
        "id": data.get("id"),
        "symbol": data.get("symbol", "").upper(),
        "name": data.get("name"),
        "image": data.get("image", {}).get("large"),
        "current_price_usd": market_data.get("current_price", {}).get("usd"),
        "current_price_twd": market_data.get("current_price", {}).get("twd"),
        "market_cap_usd": market_data.get("market_cap", {}).get("usd"),
        "market_cap_rank": market_data.get("market_cap_rank"),
        "total_volume_usd": market_data.get("total_volume", {}).get("usd"),
        "high_24h_usd": market_data.get("high_24h", {}).get("usd"),
        "low_24h_usd": market_data.get("low_24h", {}).get("usd"),
        "price_change_24h": market_data.get("price_change_24h"),
        "price_change_percentage_24h": market_data.get("price_change_percentage_24h"),
        "price_change_percentage_7d": market_data.get("price_change_percentage_7d"),
        "price_change_percentage_30d": market_data.get("price_change_percentage_30d"),
        "circulating_supply": market_data.get("circulating_supply"),
        "total_supply": market_data.get("total_supply"),
        "max_supply": market_data.get("max_supply"),
        "ath": market_data.get("ath", {}).get("usd"),
        "ath_date": market_data.get("ath_date", {}).get("usd"),
        "atl": market_data.get("atl", {}).get("usd"),
        "atl_date": market_data.get("atl_date", {}).get("usd"),
        "last_updated": data.get("last_updated")
    }

async def get_trending_coins() -> Optional[list]:
    """ç²å–ç•¶å‰ç†±é–€åŠ å¯†è²¨å¹£"""
    data = await fetch_coingecko_data("/search/trending")
    
    if not data or "coins" not in data:
        return None
    
    trending = []
    for item in data.get("coins", [])[:10]:
        coin = item.get("item", {})
        trending.append({
            "id": coin.get("id"),
            "name": coin.get("name"),
            "symbol": coin.get("symbol"),
            "market_cap_rank": coin.get("market_cap_rank"),
            "price_btc": coin.get("price_btc"),
            "thumb": coin.get("thumb")
        })
    
    return trending

async def get_nft_data(nft_id: str) -> Optional[Dict[str, Any]]:
    """ç²å– NFT ç³»åˆ—è³‡è¨Š"""
    data = await fetch_coingecko_data(f"/nfts/{nft_id}")
    
    if not data:
        return None
    
    return {
        "id": data.get("id"),
        "name": data.get("name"),
        "symbol": data.get("asset_platform_id"),
        "description": data.get("description"),
        "image": data.get("image", {}).get("small"),
        "floor_price_usd": data.get("floor_price", {}).get("usd"),
        "floor_price_native": data.get("floor_price", {}).get("native_currency"),
        "market_cap_usd": data.get("market_cap", {}).get("usd"),
        "volume_24h_usd": data.get("volume_24h", {}).get("usd"),
        "total_supply": data.get("total_supply"),
        "number_of_unique_addresses": data.get("number_of_unique_addresses"),
        "links": data.get("links", {})
    }

async def search_coingecko(query: str) -> Optional[list]:
    """åœ¨ CoinGecko æœå°‹åŠ å¯†è²¨å¹£å’Œ NFT"""
    data = await fetch_coingecko_data("/search", params={"query": query})
    
    if not data:
        return None
    
    results = []
    
    # åŠ å¯†è²¨å¹£çµæœ
    for coin in data.get("coins", [])[:5]:
        results.append({
            "type": "coin",
            "id": coin.get("id"),
            "name": coin.get("name"),
            "symbol": coin.get("symbol"),
            "market_cap_rank": coin.get("market_cap_rank"),
            "thumb": coin.get("thumb")
        })
    
    # NFT çµæœ
    for nft in data.get("nfts", [])[:3]:
        results.append({
            "type": "nft",
            "id": nft.get("id"),
            "name": nft.get("name"),
            "symbol": nft.get("symbol"),
            "thumb": nft.get("thumb")
        })
    
    return results

# AI åŠ©æ‰‹é‚è¼¯

@cl.on_chat_start
async def start():
    """èŠå¤©é–‹å§‹æ™‚çš„æ­¡è¿è¨Šæ¯"""
    welcome_message = """
ğŸ‘‹ **æ­¡è¿ä¾†åˆ° Crypto-Place AI åŠ©æ‰‹ï¼**

æˆ‘å¯ä»¥å¹«ä½ ï¼š
- ğŸ” æŸ¥è©¢åŠ å¯†è²¨å¹£å³æ™‚è³‡è¨Š
- ğŸ“Š åˆ†æå¸‚å ´è¶¨å‹¢
- ğŸ’¼ æŸ¥çœ‹ä½ çš„æ”¶è—æ¸…å–®
- ğŸ“ˆ æä¾›æŠ•è³‡å»ºè­°
- ğŸ“° ç²å–æœ€æ–°åŠ å¯†è²¨å¹£æ–°è

è«‹å•æœ‰ä»€éº¼å¯ä»¥å¹«åŠ©ä½ çš„å—ï¼Ÿ
"""
    await cl.Message(content=welcome_message).send()
    
    # å„²å­˜ç”¨æˆ¶ session
    cl.user_session.set("conversation_history", [])

@cl.on_message
async def main(message: cl.Message):
    """è™•ç†ç”¨æˆ¶è¨Šæ¯"""
    user_query = message.content
    user_query_lower = user_query.lower()
    user_token = cl.user_session.get("jwt_token")  # å¾ session ç²å– JWT
    user_id = cl.user_session.get("user_id", "anonymous")  # ç²å–ç”¨æˆ¶ ID

    # å»ºç«‹ Langfuse trace (æ•´å€‹å°è©±çš„è¿½è¹¤)
    langfuse_trace = None
    if langfuse_enabled and LANGFUSE_AVAILABLE:
        try:
            langfuse_client = get_client()
            langfuse_trace = langfuse_client.trace(
                name="chat_conversation",
                user_id=user_id,
                input=user_query,  # ç”¨æˆ¶åŸå§‹è¨Šæ¯ä½œç‚º input
                session_id=cl.user_session.get("id", None),
                metadata={
                    "source": "chainlit",
                    "model": gemini_manager.current_model
                }
            )
        except Exception as lf_err:
            print(f"âš ï¸ Langfuse trace å»ºç«‹å¤±æ•—: {lf_err}")

    # é¡¯ç¤ºæ­£åœ¨è™•ç†çš„è¨Šæ¯
    processing_msg = cl.Message(content="ğŸ” æ­£åœ¨æŸ¥è©¢è³‡æ–™...")
    await processing_msg.send()

    try:
        crypto_data = None
        response = None

        # æª¢æ¸¬æ˜¯å¦è©¢å•åƒ¹æ ¼ã€å¸‚å ´è³‡è¨Šç­‰
        is_price_query = any(keyword in user_query_lower for keyword in [
            "åƒ¹æ ¼", "price", "å¤šå°‘", "å¸‚å€¼", "å¸‚å ´", "æ¼²", "è·Œ", "æ³¢å‹•"
        ])

        # æª¢æ¸¬æ˜¯å¦è©¢å•ç†±é–€è¶¨å‹¢
        is_trending_query = any(keyword in user_query_lower for keyword in [
            "ç†±é–€", "trending", "è¶¨å‹¢", "æµè¡Œ"
        ])

        # æª¢æ¸¬æ˜¯å¦è©¢å• NFT
        is_nft_query = any(keyword in user_query_lower for keyword in [
            "nft", "éåŒè³ªåŒ–ä»£å¹£", "è—è¡“å“"
        ])

        # å¸¸è¦‹åŠ å¯†è²¨å¹£ ID æ˜ å°„
        crypto_map = {
            "bitcoin": ["bitcoin", "btc", "æ¯”ç‰¹å¹£"],
            "ethereum": ["ethereum", "eth", "ä»¥å¤ªåŠ", "ä»¥å¤ªå¹£"],
            "binancecoin": ["bnb", "binance", "å¹£å®‰å¹£"],
            "solana": ["solana", "sol"],
            "cardano": ["cardano", "ada"],
            "ripple": ["ripple", "xrp", "ç‘æ³¢å¹£"],
            "dogecoin": ["dogecoin", "doge", "ç‹—ç‹—å¹£"],
            "polkadot": ["polkadot", "dot"],
            "avalanche-2": ["avalanche", "avax"],
            "chainlink": ["chainlink", "link"]
        }

        # è­˜åˆ¥ç”¨æˆ¶æƒ³æŸ¥è©¢çš„åŠ å¯†è²¨å¹£
        detected_coin = None
        for coin_id, keywords in crypto_map.items():
            if any(keyword in user_query_lower for keyword in keywords):
                detected_coin = coin_id
                break

        # è™•ç†ç†±é–€è¶¨å‹¢æŸ¥è©¢
        if is_trending_query:
            processing_msg.content = "ğŸ“Š æ­£åœ¨ç²å–ç†±é–€åŠ å¯†è²¨å¹£..."
            await processing_msg.update()

            trending = await get_trending_coins()
            if trending:
                response = await generate_ai_response_with_data(
                    user_query,
                    {"trending_coins": trending},
                    user_id,
                    langfuse_trace
                )

        # è™•ç†ç‰¹å®šåŠ å¯†è²¨å¹£æŸ¥è©¢
        elif detected_coin and is_price_query:
            processing_msg.content = f"ğŸ’° æ­£åœ¨ç²å– {detected_coin} å³æ™‚è³‡æ–™..."
            await processing_msg.update()

            crypto_data = await get_crypto_price(detected_coin)
            if crypto_data:
                response = await generate_ai_response_with_data(
                    user_query,
                    {"crypto_data": crypto_data},
                    user_id,
                    langfuse_trace
                )

        # è™•ç†æ”¶è—æ¸…å–®æŸ¥è©¢
        elif any(keyword in user_query_lower for keyword in ["watchlist", "æ”¶è—", "æ¸…å–®", "è¿½è¹¤"]):
            response = await handle_watchlist_query(user_token)

        # è™•ç†æœå°‹æŸ¥è©¢
        elif any(keyword in user_query_lower for keyword in ["search", "æœå°‹", "æ‰¾", "æŸ¥"]) and not is_price_query:
            # æå–æœå°‹é—œéµå­—
            search_term = user_query_lower
            for word in ["search", "æœå°‹", "æ‰¾", "æŸ¥"]:
                search_term = search_term.replace(word, "").strip()

            processing_msg.content = f"ğŸ” æ­£åœ¨æœå°‹ {search_term}..."
            await processing_msg.update()

            results = await search_coingecko(search_term)
            if results:
                response = await generate_ai_response_with_data(
                    user_query,
                    {"search_results": results, "query": search_term},
                    user_id,
                    langfuse_trace
                )

        # å¦‚æœæ²’æœ‰ç‰¹å®šè™•ç†,ä½¿ç”¨ AI é€šç”¨å›ç­”
        if not response:
            processing_msg.content = "ğŸ¤” æ­£åœ¨æ€è€ƒ..."
            await processing_msg.update()
            response = await generate_ai_response(user_query, user_id=user_id, parent_trace=langfuse_trace)

        # æ›´æ–°è¨Šæ¯å…§å®¹
        processing_msg.content = response
        await processing_msg.update()

        # æ›´æ–° Langfuse trace çš„ output ä¸¦ flush
        if langfuse_trace:
            try:
                langfuse_trace.update(output=response)
                # ç¢ºä¿æ•¸æ“šè¢«ç™¼é€åˆ° Langfuse ä¼ºæœå™¨
                langfuse_client = get_client()
                langfuse_client.flush()
            except Exception as lf_err:
                print(f"âš ï¸ Langfuse trace æ›´æ–°å¤±æ•—: {lf_err}")

    except Exception as e:
        error_message = f"âŒ æŠ±æ­‰ï¼Œç™¼ç”ŸéŒ¯èª¤: {str(e)}"
        processing_msg.content = error_message
        await processing_msg.update()

        # è¨˜éŒ„éŒ¯èª¤åˆ° Langfuse
        if langfuse_trace:
            try:
                langfuse_trace.update(
                    output=error_message,
                    metadata={"error": str(e), "status": "error"}
                )
            except:
                pass

# æŸ¥è©¢è™•ç†å‡½æ•¸

async def handle_coin_query(coin_id: str) -> str:
    """è™•ç†åŠ å¯†è²¨å¹£æŸ¥è©¢"""
    coin_data = await get_coin_data(coin_id)
    
    if not coin_data:
        return f"âŒ ç„¡æ³•ç²å– {coin_id} çš„æ•¸æ“šï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
    
    # æ ¼å¼åŒ–å›æ‡‰
    price_change = coin_data.get('price_change_percentage_24h', 0)
    emoji = "ğŸ“ˆ" if price_change > 0 else "ğŸ“‰"
    
    response = f"""
{emoji} **{coin_data.get('name', coin_id)} ({coin_data.get('symbol', '').upper()})** å¸‚å ´è³‡è¨Š

ğŸ’° **ç•¶å‰åƒ¹æ ¼**: ${coin_data.get('current_price', 0):,.2f}
ğŸ“Š **24å°æ™‚æ¼²è·Œ**: {price_change:+.2f}%
ğŸ’ **å¸‚å€¼**: ${coin_data.get('market_cap', 0):,.0f}
ğŸ“Š **24å°æ™‚äº¤æ˜“é‡**: ${coin_data.get('total_volume', 0):,.0f}
ğŸ“ˆ **24å°æ™‚æœ€é«˜**: ${coin_data.get('high_24h', 0):,.2f}
ğŸ“‰ **24å°æ™‚æœ€ä½**: ${coin_data.get('low_24h', 0):,.2f}

---
ğŸ’¡ éœ€è¦æ›´å¤šè³‡è¨Šæˆ–åˆ†æå—ï¼Ÿ
"""
    return response

async def handle_watchlist_query(token: Optional[str]) -> str:
    """è™•ç† watchlist æŸ¥è©¢"""
    if not token:
        return "âš ï¸ è«‹å…ˆç™»å…¥æ‰èƒ½æŸ¥çœ‹æ”¶è—æ¸…å–®ã€‚"
    
    watchlist = await get_user_watchlist(token)
    
    if not watchlist or len(watchlist) == 0:
        return "ğŸ“‹ ä½ çš„æ”¶è—æ¸…å–®ç›®å‰æ˜¯ç©ºçš„ã€‚\n\nè©¦è©¦æœå°‹ä½ æ„Ÿèˆˆè¶£çš„åŠ å¯†è²¨å¹£ä¸¦åŠ å…¥æ”¶è—å§ï¼"
    
    response = "ğŸ“‹ **ä½ çš„æ”¶è—æ¸…å–®**\n\n"
    for idx, item in enumerate(watchlist[:10], 1):  # æœ€å¤šé¡¯ç¤º10å€‹
        response += f"{idx}. {item['coinName']} ({item['symbol'].upper()})\n"
    
    if len(watchlist) > 10:
        response += f"\n... é‚„æœ‰ {len(watchlist) - 10} å€‹æ”¶è—"
    
    return response

async def handle_search_query(query: str) -> str:
    """è™•ç†æœå°‹æŸ¥è©¢"""
    results = await search_coins(query)
    
    if not results or len(results) == 0:
        return f"ğŸ” æ‰¾ä¸åˆ°èˆ‡ '{query}' ç›¸é—œçš„åŠ å¯†è²¨å¹£ã€‚"
    
    response = f"ğŸ” **æœå°‹çµæœ: '{query}'**\n\n"
    for idx, coin in enumerate(results[:5], 1):  # æœ€å¤šé¡¯ç¤º5å€‹çµæœ
        response += f"{idx}. {coin['name']} ({coin['symbol'].upper()})\n"
    
    return response

# Langfuse v3 æ•´åˆ - ä½¿ç”¨ parent_trace ä¸²è¯è¿½è¹¤
async def generate_ai_response(query: str, user_id: str = None, parent_trace=None) -> str:
    """ä½¿ç”¨ Google Gemini ç”Ÿæˆ AI å›ç­”"""
    return await _generate_ai_response_impl(query, user_id, parent_trace)

async def generate_ai_response_with_data(query: str, data: Dict[str, Any], user_id: str = None, parent_trace=None) -> str:
    """ä½¿ç”¨ Google Gemini ç”Ÿæˆ AI å›ç­”,ä¸¦å¸¶å…¥å³æ™‚è³‡æ–™"""
    return await _generate_ai_response_with_data_impl(query, data, user_id, parent_trace)

async def _generate_ai_response_with_data_impl(query: str, data: Dict[str, Any], user_id: str = None, parent_trace=None) -> str:
    """AI å›ç­”ç”Ÿæˆçš„å¯¦éš›å¯¦ä½œ (å¸¶å³æ™‚è³‡æ–™)"""
    start_time = time.time()
    langfuse_generation = None

    try:
        import json

        # å»ºç«‹ç³»çµ±æç¤ºè©
        system_prompt = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„åŠ å¯†è²¨å¹£æŠ•è³‡é¡§å•ï¼Œåå« Crypto Assistantã€‚
ä½ çš„ç‰¹é»ï¼š
- ç”¨ç¹é«”ä¸­æ–‡å›ç­”
- å°ˆæ¥­ä½†å‹å–„
- æä¾›æº–ç¢ºçš„å¸‚å ´åˆ†æ
- çµ¦äºˆå¯¦ç”¨çš„æŠ•è³‡å»ºè­°
- å¿…è¦æ™‚æœƒæé†’é¢¨éšª
- ä½¿ç”¨æä¾›çš„å³æ™‚å¸‚å ´è³‡æ–™ä¾†å›ç­”å•é¡Œ

é‡è¦æé†’ï¼š
- åƒ¹æ ¼é¡¯ç¤ºè«‹ä½¿ç”¨ç¾å…ƒ (USD) ä¸¦åŠ ä¸Šåƒåˆ†ä½ç¬¦è™Ÿ
- æ¼²è·Œå¹…åº¦è«‹é¡¯ç¤ºç‚ºç™¾åˆ†æ¯”ï¼Œä¸¦æ¨™è¨»æ­£è² è™Ÿ
- æä¾›æ•¸æ“šä¾†æºç‚º CoinGecko
- é©æ™‚æé†’æŠ•è³‡é¢¨éšª
"""

        # æ ¼å¼åŒ–è³‡æ–™ç‚ºæ˜“è®€æ–‡å­—
        data_text = "\n\n--- å³æ™‚å¸‚å ´è³‡æ–™ (ä¾†è‡ª CoinGecko) ---\n"
        data_text += json.dumps(data, ensure_ascii=False, indent=2)

        # çµ„åˆå®Œæ•´çš„æç¤ºè©
        full_prompt = f"{system_prompt}\n\nç”¨æˆ¶å•é¡Œ: {query}{data_text}\n\nè«‹æ ¹æ“šä»¥ä¸Šå³æ™‚è³‡æ–™,ç”¨å°ˆæ¥­ä¸”å‹å–„çš„æ–¹å¼å›ç­”ç”¨æˆ¶å•é¡Œã€‚"

        # Langfuse v3 è¿½è¹¤ - ä½¿ç”¨ parent_trace å»ºç«‹ generation (å­é …)
        if langfuse_enabled and LANGFUSE_AVAILABLE and parent_trace:
            try:
                langfuse_generation = parent_trace.generation(
                    name="gemini_llm_call",
                    model=gemini_manager.current_model,
                    input=full_prompt,
                    metadata={
                        "query": query,
                        "has_market_data": True,
                        "data_keys": list(data.keys())
                    }
                )
            except Exception as lf_err:
                print(f"âš ï¸ Langfuse generation å»ºç«‹å¤±æ•—: {lf_err}")

        # èª¿ç”¨ Gemini API
        response = gemini_model.generate_content(full_prompt)
        response_text = response.text

        # è¨ˆç®—åŸ·è¡Œæ™‚é–“
        duration = time.time() - start_time

        # æ›´æ–° Langfuse generation
        if langfuse_generation:
            try:
                langfuse_generation.end(
                    output=response_text,
                    metadata={
                        "status": "success",
                        "response_length": len(response_text),
                        "duration_seconds": round(duration, 2),
                        "model_used": gemini_manager.current_model
                    }
                )
            except Exception as lf_err:
                print(f"âš ï¸ Langfuse generation æ›´æ–°å¤±æ•—: {lf_err}")

        return response_text

    except Exception as e:
        error_message = f"âŒ AI å›ç­”ç”Ÿæˆå¤±æ•—: {str(e)}"

        # è¨˜éŒ„éŒ¯èª¤åˆ° Langfuse
        if langfuse_generation:
            try:
                langfuse_generation.end(
                    output=error_message,
                    metadata={
                        "status": "error",
                        "error": str(e),
                        "duration_seconds": round(time.time() - start_time, 2)
                    },
                    level="ERROR"
                )
            except:
                pass

        return error_message

async def _generate_ai_response_impl(query: str, user_id: str = None, parent_trace=None) -> str:
    """AI å›ç­”ç”Ÿæˆçš„å¯¦éš›å¯¦ä½œ"""
    start_time = time.time()
    langfuse_generation = None

    try:
        # å»ºç«‹ç³»çµ±æç¤ºè©
        system_prompt = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„åŠ å¯†è²¨å¹£æŠ•è³‡é¡§å•ï¼Œåå« Crypto Assistantã€‚
ä½ çš„ç‰¹é»ï¼š
- ç”¨ç¹é«”ä¸­æ–‡å›ç­”
- å°ˆæ¥­ä½†å‹å–„
- æä¾›æº–ç¢ºçš„å¸‚å ´åˆ†æ
- çµ¦äºˆå¯¦ç”¨çš„æŠ•è³‡å»ºè­°
- å¿…è¦æ™‚æœƒæé†’é¢¨éšª
"""

        # çµ„åˆå®Œæ•´çš„æç¤ºè©
        full_prompt = f"{system_prompt}\n\nç”¨æˆ¶å•é¡Œ: {query}"

        # Langfuse v3 è¿½è¹¤ - ä½¿ç”¨ parent_trace å»ºç«‹ generation (å­é …)
        if langfuse_enabled and LANGFUSE_AVAILABLE and parent_trace:
            try:
                langfuse_generation = parent_trace.generation(
                    name="gemini_llm_call",
                    model=gemini_manager.current_model,
                    input=full_prompt,
                    metadata={"query": query}
                )
            except Exception as lf_err:
                print(f"âš ï¸ Langfuse generation å»ºç«‹å¤±æ•—: {lf_err}")

        # èª¿ç”¨ Gemini API
        response = gemini_model.generate_content(full_prompt)
        response_text = response.text

        # è¨ˆç®—åŸ·è¡Œæ™‚é–“
        duration = time.time() - start_time

        # æ›´æ–° Langfuse generation
        if langfuse_generation:
            try:
                langfuse_generation.end(
                    output=response_text,
                    metadata={
                        "status": "success",
                        "response_length": len(response_text),
                        "duration_seconds": round(duration, 2),
                        "model_used": gemini_manager.current_model
                    }
                )
            except Exception as lf_err:
                print(f"âš ï¸ Langfuse generation æ›´æ–°å¤±æ•—: {lf_err}")

        return response_text

    except Exception as e:
        error_message = f"âŒ AI å›ç­”ç”Ÿæˆå¤±æ•—: {str(e)}"

        # è¨˜éŒ„éŒ¯èª¤åˆ° Langfuse
        if langfuse_generation:
            try:
                langfuse_generation.end(
                    output=error_message,
                    metadata={
                        "status": "error",
                        "error": str(e),
                        "duration_seconds": round(time.time() - start_time, 2)
                    },
                    level="ERROR"
                )
            except:
                pass

        return error_message

# éŒ¯èª¤è™•ç†

@cl.on_chat_end
async def end():
    """èŠå¤©çµæŸæ™‚çš„è™•ç†"""
    await cl.Message(content="ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ Crypto-Place AI åŠ©æ‰‹ï¼").send()

if __name__ == "__main__":
    # æœ¬åœ°æ¸¬è©¦ç”¨
    print("ğŸš€ Chainlit AI Service Started")
    print(f"ğŸ“¡ NestJS API: {NESTJS_API}")
